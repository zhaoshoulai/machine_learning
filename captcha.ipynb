{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from captcha.image import ImageCaptcha\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'q', 'v', 'n']\n"
     ]
    }
   ],
   "source": [
    "alphabet = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "def random_captcha_text(char_set=alphabet,captcha_size=4):\n",
    "    captcha_text = []\n",
    "    for i in range(captcha_size):\n",
    "        c = random.choice(char_set)\n",
    "        captcha_text.append(c)\n",
    "    return captcha_text\n",
    "\n",
    "print(random_captcha_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 128\n",
    "def gen_captcha_text_and_image():\n",
    "    image =  ImageCaptcha()\n",
    "    captcha_text = random_captcha_text()\n",
    "    captcha_text =  ''.join(captcha_text)\n",
    "    \n",
    "    captcha = image.generate(captcha_text)\n",
    "    # 变成灰度图像convert('L')\n",
    "    captcha_image = Image.open(captcha).convert('L')\n",
    "    # 裁剪缩放图片\n",
    "    box = (0,0,128,60)\n",
    "    captcha_image = captcha_image.crop(box)\n",
    "    captcha_image = captcha_image.resize((IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "    # 转化成 np.array类型\n",
    "    captcha_image = np.array(captcha_image)\n",
    "    return captcha_text, captcha_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd']\n"
     ]
    }
   ],
   "source": [
    "MAX_CAPTCHA = 4\n",
    "CHAR_SET_LEN = len(alphabet)\n",
    "\n",
    "def text2vec(text):\n",
    "    text_len = len(text)\n",
    "    if text_len > len(text):\n",
    "        raise ValueError('验证码最长4个字符')\n",
    "    \n",
    "    vector = np.zeros(MAX_CAPTCHA * CHAR_SET_LEN)\n",
    "    \n",
    "    for i,c in enumerate(text):\n",
    "        idx = i * CHAR_SET_LEN + ord(c) - 97\n",
    "        vector[idx] =  1\n",
    "    return vector\n",
    "    \n",
    "def vec2text(vec):\n",
    "    text = []\n",
    "    for i,c in enumerate(vec):\n",
    "        if c == 1:\n",
    "            idx = i % CHAR_SET_LEN\n",
    "            text.append(chr(idx+97))\n",
    "    return text\n",
    "\n",
    "print(vec2text(text2vec('abcd')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plt_image(image):\n",
    "    f = plt.figure()\n",
    "    ax = f.add_subplot(111)\n",
    "    ax.text(0.1, 0.9, text, ha='center', va='center', transform=ax.transAxes)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "if __name__== '__main__':\n",
    "    text, image = gen_captcha_text_and_image()\n",
    "    plt_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成一个训练batch\n",
    "def get_next_batch(batch_size=128):\n",
    "    batch_x = np.zeros([batch_size, IMAGE_HEIGHT * IMAGE_WIDTH])\n",
    "    batch_y = np.zeros([batch_size, MAX_CAPTCHA * CHAR_SET_LEN])\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        text, image = gen_captcha_text_and_image()\n",
    "        batch_x[i, :] = image.flatten() / 255  # (image.flatten()-128)/128  mean为0\n",
    "        batch_y[i, :] = text2vec(text)\n",
    "    \n",
    "    return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, IMAGE_HEIGHT * IMAGE_WIDTH])\n",
    "Y = tf.placeholder(tf.float32, [None, MAX_CAPTCHA * CHAR_SET_LEN])\n",
    "keep_prob = tf.placeholder(tf.float32)  # dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义CNN\n",
    "def crack_captcha_cnn(w_alpha=0.01, b_alpha=0.1):\n",
    "    x = tf.reshape(X, shape=[-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n",
    "\n",
    "    # w_c1_alpha = np.sqrt(2.0/(IMAGE_HEIGHT*IMAGE_WIDTH)) #\n",
    "    # w_c2_alpha = np.sqrt(2.0/(3*3*32))\n",
    "    # w_c3_alpha = np.sqrt(2.0/(3*3*64))\n",
    "    # w_d1_alpha = np.sqrt(2.0/(8*32*64))\n",
    "    # out_alpha  = np.sqrt(2.0/1024)\n",
    "\n",
    "    # 3 conv layer\n",
    "    # [3, 3, 1, 32] 卷积核高度，宽度，输入通道数，输出通道数\n",
    "    w_c1 = tf.Variable(w_alpha * tf.random_normal([3, 3, 1, 32]))\n",
    "    b_c1 = tf.Variable(b_alpha * tf.random_normal([32]))\n",
    "    conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c1, strides=[1, 1, 1, 1], padding='SAME'), b_c1))\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "    \n",
    "    w_c2 = tf.Variable(w_alpha * tf.random_normal([3, 3, 32, 64]))\n",
    "    b_c2 = tf.Variable(b_alpha * tf.random_normal([64]))\n",
    "    conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv1, w_c2, strides=[1, 1, 1, 1], padding='SAME'), b_c2))\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "\n",
    "    w_c3 = tf.Variable(w_alpha * tf.random_normal([3, 3, 64, 64]))\n",
    "    b_c3 = tf.Variable(b_alpha * tf.random_normal([64]))\n",
    "    conv3 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv2, w_c3, strides=[1, 1, 1, 1], padding='SAME'), b_c3))\n",
    "    conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    conv3 = tf.nn.dropout(conv3, keep_prob)\n",
    "\n",
    "    # Fully connected layer\n",
    "    w_d = tf.Variable(w_alpha * tf.random_normal([4 * 16 * 64, 1024]))\n",
    "    b_d = tf.Variable(b_alpha * tf.random_normal([1024]))\n",
    "    dense = tf.reshape(conv3, [-1, w_d.get_shape().as_list()[0]])\n",
    "    dense = tf.nn.relu(tf.add(tf.matmul(dense, w_d), b_d))\n",
    "    dense = tf.nn.dropout(dense, keep_prob)\n",
    "\n",
    "    w_out = tf.Variable(w_alpha * tf.random_normal([1024, MAX_CAPTCHA * CHAR_SET_LEN]))\n",
    "    b_out = tf.Variable(b_alpha * tf.random_normal([MAX_CAPTCHA * CHAR_SET_LEN]))\n",
    "    out = tf.add(tf.matmul(dense, w_out), b_out)\n",
    "    # out = tf.nn.softmax(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-25 17:44:09 0 0.69272864\n",
      "***************************************************************第0次的准确率为0.035\n",
      "2018-06-25 17:44:11 1 0.6144111\n",
      "2018-06-25 17:44:11 2 0.47449255\n",
      "2018-06-25 17:44:12 3 0.2921394\n",
      "2018-06-25 17:44:13 4 0.17114115\n",
      "2018-06-25 17:44:13 5 0.19308046\n",
      "2018-06-25 17:44:14 6 0.25449356\n",
      "2018-06-25 17:44:15 7 0.27894992\n",
      "2018-06-25 17:44:15 8 0.27398747\n",
      "2018-06-25 17:44:16 9 0.24808127\n",
      "2018-06-25 17:44:17 10 0.22125076\n",
      "2018-06-25 17:44:17 11 0.18905245\n",
      "2018-06-25 17:44:18 12 0.17088641\n",
      "2018-06-25 17:44:19 13 0.17092857\n",
      "2018-06-25 17:44:19 14 0.18055993\n",
      "2018-06-25 17:44:20 15 0.19479662\n",
      "2018-06-25 17:44:21 16 0.19727707\n",
      "2018-06-25 17:44:21 17 0.19349296\n",
      "2018-06-25 17:44:22 18 0.18463916\n",
      "2018-06-25 17:44:23 19 0.17504247\n",
      "2018-06-25 17:44:23 20 0.16819316\n",
      "2018-06-25 17:44:24 21 0.16520545\n",
      "2018-06-25 17:44:24 22 0.16680238\n",
      "2018-06-25 17:44:25 23 0.17139322\n",
      "2018-06-25 17:44:26 24 0.17428987\n",
      "2018-06-25 17:44:26 25 0.17470749\n",
      "2018-06-25 17:44:27 26 0.17688195\n",
      "2018-06-25 17:44:28 27 0.17656063\n",
      "2018-06-25 17:44:28 28 0.16945498\n",
      "2018-06-25 17:44:29 29 0.16869578\n",
      "2018-06-25 17:44:30 30 0.1665944\n",
      "2018-06-25 17:44:30 31 0.16725236\n",
      "2018-06-25 17:44:31 32 0.16938445\n",
      "2018-06-25 17:44:32 33 0.16785195\n",
      "2018-06-25 17:44:32 34 0.17010252\n",
      "2018-06-25 17:44:33 35 0.16980508\n",
      "2018-06-25 17:44:33 36 0.16826195\n",
      "2018-06-25 17:44:34 37 0.16670868\n",
      "2018-06-25 17:44:35 38 0.16504724\n",
      "2018-06-25 17:44:35 39 0.16393088\n",
      "2018-06-25 17:44:36 40 0.16489671\n",
      "2018-06-25 17:44:37 41 0.16457799\n",
      "2018-06-25 17:44:37 42 0.16623332\n",
      "2018-06-25 17:44:38 43 0.16602978\n",
      "2018-06-25 17:44:38 44 0.16748777\n",
      "2018-06-25 17:44:39 45 0.16792879\n",
      "2018-06-25 17:44:40 46 0.16597414\n",
      "2018-06-25 17:44:40 47 0.16634625\n",
      "2018-06-25 17:44:41 48 0.16701183\n",
      "2018-06-25 17:44:42 49 0.16565257\n",
      "2018-06-25 17:44:42 50 0.16615461\n",
      "2018-06-25 17:44:43 51 0.16611627\n",
      "2018-06-25 17:44:44 52 0.16589275\n",
      "2018-06-25 17:44:44 53 0.16585277\n",
      "2018-06-25 17:44:45 54 0.16449387\n",
      "2018-06-25 17:44:45 55 0.16504952\n",
      "2018-06-25 17:44:46 56 0.16452664\n",
      "2018-06-25 17:44:47 57 0.164828\n",
      "2018-06-25 17:44:47 58 0.16512193\n",
      "2018-06-25 17:44:48 59 0.16598941\n",
      "2018-06-25 17:44:49 60 0.16523123\n",
      "2018-06-25 17:44:49 61 0.16641508\n",
      "2018-06-25 17:44:50 62 0.16533278\n",
      "2018-06-25 17:44:50 63 0.16508938\n",
      "2018-06-25 17:44:51 64 0.1653547\n",
      "2018-06-25 17:44:52 65 0.16518275\n",
      "2018-06-25 17:44:52 66 0.1654976\n",
      "2018-06-25 17:44:53 67 0.16468638\n",
      "2018-06-25 17:44:54 68 0.16619119\n",
      "2018-06-25 17:44:54 69 0.16281964\n",
      "2018-06-25 17:44:55 70 0.16508667\n",
      "2018-06-25 17:44:55 71 0.16437009\n",
      "2018-06-25 17:44:56 72 0.16399357\n",
      "2018-06-25 17:44:57 73 0.16484205\n",
      "2018-06-25 17:44:57 74 0.16577172\n",
      "2018-06-25 17:44:58 75 0.16485724\n",
      "2018-06-25 17:44:59 76 0.16418067\n",
      "2018-06-25 17:44:59 77 0.16483308\n",
      "2018-06-25 17:45:00 78 0.16701926\n",
      "2018-06-25 17:45:01 79 0.16550244\n",
      "2018-06-25 17:45:01 80 0.16558012\n",
      "2018-06-25 17:45:02 81 0.16603361\n",
      "2018-06-25 17:45:03 82 0.16505323\n",
      "2018-06-25 17:45:03 83 0.16362765\n",
      "2018-06-25 17:45:04 84 0.16632639\n",
      "2018-06-25 17:45:04 85 0.16543087\n",
      "2018-06-25 17:45:05 86 0.1649699\n",
      "2018-06-25 17:45:06 87 0.16625308\n",
      "2018-06-25 17:45:06 88 0.16453134\n",
      "2018-06-25 17:45:07 89 0.16408421\n",
      "2018-06-25 17:45:08 90 0.16382112\n",
      "2018-06-25 17:45:08 91 0.16477743\n",
      "2018-06-25 17:45:09 92 0.16635957\n",
      "2018-06-25 17:45:09 93 0.16519043\n",
      "2018-06-25 17:45:10 94 0.16414608\n",
      "2018-06-25 17:45:11 95 0.16553187\n",
      "2018-06-25 17:45:11 96 0.16519955\n",
      "2018-06-25 17:45:12 97 0.16481188\n",
      "2018-06-25 17:45:13 98 0.16615207\n",
      "2018-06-25 17:45:13 99 0.16533883\n",
      "2018-06-25 17:45:14 100 0.16441593\n",
      "***************************************************************第100次的准确率为0.065\n",
      "2018-06-25 17:45:15 101 0.16533925\n",
      "2018-06-25 17:45:16 102 0.16449858\n",
      "2018-06-25 17:45:16 103 0.16524635\n",
      "2018-06-25 17:45:17 104 0.16540582\n",
      "2018-06-25 17:45:18 105 0.16549675\n",
      "2018-06-25 17:45:18 106 0.16415808\n",
      "2018-06-25 17:45:19 107 0.16584572\n",
      "2018-06-25 17:45:20 108 0.16500752\n",
      "2018-06-25 17:45:20 109 0.16522771\n",
      "2018-06-25 17:45:21 110 0.16446708\n",
      "2018-06-25 17:45:22 111 0.16474009\n",
      "2018-06-25 17:45:22 112 0.16523713\n",
      "2018-06-25 17:45:23 113 0.1651608\n",
      "2018-06-25 17:45:24 114 0.16431522\n",
      "2018-06-25 17:45:24 115 0.16534247\n",
      "2018-06-25 17:45:25 116 0.16474918\n",
      "2018-06-25 17:45:26 117 0.16510923\n",
      "2018-06-25 17:45:26 118 0.1646805\n",
      "2018-06-25 17:45:27 119 0.16636679\n",
      "2018-06-25 17:45:28 120 0.16587003\n",
      "2018-06-25 17:45:28 121 0.16538371\n",
      "2018-06-25 17:45:29 122 0.1644133\n",
      "2018-06-25 17:45:30 123 0.16411829\n",
      "2018-06-25 17:45:30 124 0.16478793\n",
      "2018-06-25 17:45:31 125 0.1648714\n",
      "2018-06-25 17:45:32 126 0.16572358\n",
      "2018-06-25 17:45:32 127 0.16454619\n",
      "2018-06-25 17:45:33 128 0.1652314\n",
      "2018-06-25 17:45:34 129 0.16464926\n",
      "2018-06-25 17:45:34 130 0.16446751\n",
      "2018-06-25 17:45:35 131 0.164508\n",
      "2018-06-25 17:45:35 132 0.16509382\n",
      "2018-06-25 17:45:36 133 0.16336152\n",
      "2018-06-25 17:45:37 134 0.16457\n",
      "2018-06-25 17:45:37 135 0.16549405\n",
      "2018-06-25 17:45:38 136 0.16391015\n",
      "2018-06-25 17:45:39 137 0.16440353\n",
      "2018-06-25 17:45:39 138 0.16438414\n",
      "2018-06-25 17:45:40 139 0.16481668\n",
      "2018-06-25 17:45:40 140 0.16615105\n",
      "2018-06-25 17:45:41 141 0.16389853\n",
      "2018-06-25 17:45:42 142 0.16398767\n",
      "2018-06-25 17:45:42 143 0.1660025\n",
      "2018-06-25 17:45:43 144 0.16443692\n",
      "2018-06-25 17:45:44 145 0.16367985\n",
      "2018-06-25 17:45:44 146 0.16563533\n",
      "2018-06-25 17:45:45 147 0.16428658\n",
      "2018-06-25 17:45:46 148 0.16533598\n",
      "2018-06-25 17:45:46 149 0.16387017\n",
      "2018-06-25 17:45:47 150 0.16485313\n",
      "2018-06-25 17:45:48 151 0.16463217\n",
      "2018-06-25 17:45:48 152 0.16371012\n",
      "2018-06-25 17:45:49 153 0.16467589\n",
      "2018-06-25 17:45:49 154 0.16542302\n",
      "2018-06-25 17:45:50 155 0.16487433\n",
      "2018-06-25 17:45:51 156 0.16421516\n",
      "2018-06-25 17:45:51 157 0.1653046\n",
      "2018-06-25 17:45:52 158 0.1654443\n",
      "2018-06-25 17:45:53 159 0.16318344\n",
      "2018-06-25 17:45:53 160 0.1638516\n",
      "2018-06-25 17:45:54 161 0.16556644\n",
      "2018-06-25 17:45:54 162 0.16452415\n",
      "2018-06-25 17:45:55 163 0.16464487\n",
      "2018-06-25 17:45:56 164 0.16532534\n",
      "2018-06-25 17:45:56 165 0.16452545\n",
      "2018-06-25 17:45:57 166 0.16352636\n",
      "2018-06-25 17:45:58 167 0.1642163\n",
      "2018-06-25 17:45:58 168 0.16290015\n",
      "2018-06-25 17:45:59 169 0.16561243\n",
      "2018-06-25 17:46:00 170 0.16510722\n",
      "2018-06-25 17:46:00 171 0.16573559\n",
      "2018-06-25 17:46:01 172 0.16643128\n",
      "2018-06-25 17:46:02 173 0.16434798\n",
      "2018-06-25 17:46:02 174 0.16578902\n",
      "2018-06-25 17:46:03 175 0.16325055\n",
      "2018-06-25 17:46:04 176 0.16456454\n",
      "2018-06-25 17:46:04 177 0.16644485\n",
      "2018-06-25 17:46:05 178 0.16523273\n",
      "2018-06-25 17:46:05 179 0.16537355\n",
      "2018-06-25 17:46:06 180 0.16496173\n",
      "2018-06-25 17:46:07 181 0.16492721\n",
      "2018-06-25 17:46:07 182 0.16584052\n",
      "2018-06-25 17:46:08 183 0.16399391\n",
      "2018-06-25 17:46:09 184 0.16413797\n",
      "2018-06-25 17:46:09 185 0.16619566\n",
      "2018-06-25 17:46:10 186 0.16490911\n",
      "2018-06-25 17:46:10 187 0.16395661\n",
      "2018-06-25 17:46:11 188 0.16316356\n",
      "2018-06-25 17:46:12 189 0.16450462\n",
      "2018-06-25 17:46:12 190 0.16500689\n",
      "2018-06-25 17:46:13 191 0.1639452\n",
      "2018-06-25 17:46:14 192 0.16541097\n",
      "2018-06-25 17:46:14 193 0.16438858\n",
      "2018-06-25 17:46:15 194 0.16400787\n",
      "2018-06-25 17:46:16 195 0.16527759\n",
      "2018-06-25 17:46:16 196 0.16415101\n",
      "2018-06-25 17:46:17 197 0.16541062\n",
      "2018-06-25 17:46:18 198 0.16533902\n",
      "2018-06-25 17:46:18 199 0.16452383\n",
      "2018-06-25 17:46:19 200 0.16452098\n",
      "***************************************************************第200次的准确率为0.0325\n",
      "2018-06-25 17:46:20 201 0.16430031\n",
      "2018-06-25 17:46:21 202 0.16430403\n",
      "2018-06-25 17:46:21 203 0.16424754\n",
      "2018-06-25 17:46:22 204 0.16492176\n",
      "2018-06-25 17:46:23 205 0.16307926\n",
      "2018-06-25 17:46:23 206 0.16513593\n",
      "2018-06-25 17:46:24 207 0.16442244\n",
      "2018-06-25 17:46:24 208 0.1652449\n",
      "2018-06-25 17:46:25 209 0.16556802\n",
      "2018-06-25 17:46:26 210 0.16453798\n",
      "2018-06-25 17:46:26 211 0.16381201\n",
      "2018-06-25 17:46:27 212 0.16488539\n",
      "2018-06-25 17:46:28 213 0.16437504\n",
      "2018-06-25 17:46:28 214 0.16501151\n",
      "2018-06-25 17:46:29 215 0.1645286\n",
      "2018-06-25 17:46:29 216 0.16306998\n",
      "2018-06-25 17:46:30 217 0.16391188\n",
      "2018-06-25 17:46:31 218 0.16381587\n",
      "2018-06-25 17:46:31 219 0.1646726\n",
      "2018-06-25 17:46:32 220 0.16419111\n",
      "2018-06-25 17:46:33 221 0.16522358\n",
      "2018-06-25 17:46:33 222 0.16582347\n",
      "2018-06-25 17:46:34 223 0.16550769\n",
      "2018-06-25 17:46:35 224 0.16532995\n",
      "2018-06-25 17:46:35 225 0.16424945\n",
      "2018-06-25 17:46:36 226 0.16388305\n",
      "2018-06-25 17:46:36 227 0.16475424\n",
      "2018-06-25 17:46:37 228 0.16373202\n",
      "2018-06-25 17:46:38 229 0.16376719\n",
      "2018-06-25 17:46:38 230 0.1647063\n",
      "2018-06-25 17:46:39 231 0.16488633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-25 17:46:40 232 0.16407107\n",
      "2018-06-25 17:46:40 233 0.16424003\n",
      "2018-06-25 17:46:41 234 0.1658055\n",
      "2018-06-25 17:46:41 235 0.16505462\n",
      "2018-06-25 17:46:42 236 0.16513337\n",
      "2018-06-25 17:46:43 237 0.16434774\n",
      "2018-06-25 17:46:43 238 0.16482718\n",
      "2018-06-25 17:46:44 239 0.16387261\n",
      "2018-06-25 17:46:44 240 0.1639171\n",
      "2018-06-25 17:46:45 241 0.16457707\n",
      "2018-06-25 17:46:46 242 0.16432597\n",
      "2018-06-25 17:46:46 243 0.16436519\n",
      "2018-06-25 17:46:47 244 0.16348784\n",
      "2018-06-25 17:46:48 245 0.16422158\n",
      "2018-06-25 17:46:48 246 0.16475132\n",
      "2018-06-25 17:46:49 247 0.1644701\n",
      "2018-06-25 17:46:49 248 0.16379954\n",
      "2018-06-25 17:46:50 249 0.16524678\n",
      "2018-06-25 17:46:51 250 0.16482636\n",
      "2018-06-25 17:46:51 251 0.16461016\n",
      "2018-06-25 17:46:52 252 0.16514061\n",
      "2018-06-25 17:46:53 253 0.16477905\n",
      "2018-06-25 17:46:53 254 0.16454142\n",
      "2018-06-25 17:46:54 255 0.16484053\n",
      "2018-06-25 17:46:54 256 0.16481638\n",
      "2018-06-25 17:46:55 257 0.16441426\n",
      "2018-06-25 17:46:56 258 0.16376773\n",
      "2018-06-25 17:46:56 259 0.16544925\n",
      "2018-06-25 17:46:57 260 0.16460496\n",
      "2018-06-25 17:46:58 261 0.16550937\n",
      "2018-06-25 17:46:58 262 0.16390593\n",
      "2018-06-25 17:46:59 263 0.16393797\n",
      "2018-06-25 17:47:00 264 0.16493654\n",
      "2018-06-25 17:47:00 265 0.16428636\n",
      "2018-06-25 17:47:01 266 0.164852\n",
      "2018-06-25 17:47:02 267 0.16419649\n",
      "2018-06-25 17:47:02 268 0.16508015\n",
      "2018-06-25 17:47:03 269 0.16513674\n",
      "2018-06-25 17:47:03 270 0.16464792\n",
      "2018-06-25 17:47:04 271 0.16534482\n",
      "2018-06-25 17:47:05 272 0.16476999\n",
      "2018-06-25 17:47:05 273 0.16326985\n",
      "2018-06-25 17:47:06 274 0.16523284\n",
      "2018-06-25 17:47:07 275 0.16392432\n",
      "2018-06-25 17:47:07 276 0.16410479\n",
      "2018-06-25 17:47:08 277 0.1636928\n",
      "2018-06-25 17:47:08 278 0.1637815\n",
      "2018-06-25 17:47:09 279 0.16512558\n",
      "2018-06-25 17:47:10 280 0.16383916\n",
      "2018-06-25 17:47:10 281 0.16473721\n",
      "2018-06-25 17:47:11 282 0.16536108\n",
      "2018-06-25 17:47:12 283 0.16459598\n",
      "2018-06-25 17:47:12 284 0.1642851\n",
      "2018-06-25 17:47:13 285 0.16477166\n",
      "2018-06-25 17:47:13 286 0.16417187\n",
      "2018-06-25 17:47:14 287 0.16379482\n",
      "2018-06-25 17:47:15 288 0.1653928\n",
      "2018-06-25 17:47:15 289 0.16488717\n",
      "2018-06-25 17:47:16 290 0.16331086\n",
      "2018-06-25 17:47:17 291 0.16373631\n",
      "2018-06-25 17:47:17 292 0.1646056\n",
      "2018-06-25 17:47:18 293 0.16504818\n",
      "2018-06-25 17:47:19 294 0.16528614\n",
      "2018-06-25 17:47:19 295 0.16457446\n",
      "2018-06-25 17:47:20 296 0.1634889\n",
      "2018-06-25 17:47:20 297 0.16490516\n",
      "2018-06-25 17:47:21 298 0.16328686\n",
      "2018-06-25 17:47:22 299 0.16336815\n",
      "2018-06-25 17:47:22 300 0.1643504\n",
      "***************************************************************第300次的准确率为0.0275\n",
      "2018-06-25 17:47:24 301 0.16511615\n",
      "2018-06-25 17:47:24 302 0.16414163\n",
      "2018-06-25 17:47:25 303 0.16450039\n",
      "2018-06-25 17:47:26 304 0.16454059\n",
      "2018-06-25 17:47:26 305 0.16477989\n",
      "2018-06-25 17:47:27 306 0.16399404\n",
      "2018-06-25 17:47:27 307 0.16434224\n",
      "2018-06-25 17:47:28 308 0.16497797\n",
      "2018-06-25 17:47:29 309 0.1647972\n",
      "2018-06-25 17:47:29 310 0.1643611\n",
      "2018-06-25 17:47:30 311 0.16478612\n",
      "2018-06-25 17:47:31 312 0.16424963\n",
      "2018-06-25 17:47:31 313 0.16427003\n",
      "2018-06-25 17:47:32 314 0.16414087\n",
      "2018-06-25 17:47:32 315 0.16365688\n",
      "2018-06-25 17:47:33 316 0.16314289\n",
      "2018-06-25 17:47:34 317 0.16413869\n",
      "2018-06-25 17:47:34 318 0.16397795\n",
      "2018-06-25 17:47:35 319 0.16447441\n",
      "2018-06-25 17:47:36 320 0.1645203\n",
      "2018-06-25 17:47:36 321 0.16451183\n",
      "2018-06-25 17:47:37 322 0.16391066\n",
      "2018-06-25 17:47:37 323 0.16488376\n",
      "2018-06-25 17:47:38 324 0.16452767\n",
      "2018-06-25 17:47:39 325 0.16405609\n",
      "2018-06-25 17:47:39 326 0.16384155\n",
      "2018-06-25 17:47:40 327 0.16372713\n",
      "2018-06-25 17:47:41 328 0.16368221\n",
      "2018-06-25 17:47:41 329 0.16472512\n",
      "2018-06-25 17:47:42 330 0.16362922\n",
      "2018-06-25 17:47:42 331 0.16437003\n",
      "2018-06-25 17:47:43 332 0.16383483\n",
      "2018-06-25 17:47:44 333 0.16472736\n",
      "2018-06-25 17:47:44 334 0.16448304\n",
      "2018-06-25 17:47:45 335 0.16340011\n",
      "2018-06-25 17:47:46 336 0.16435279\n",
      "2018-06-25 17:47:46 337 0.1647602\n",
      "2018-06-25 17:47:47 338 0.16361435\n",
      "2018-06-25 17:47:47 339 0.16450408\n",
      "2018-06-25 17:47:48 340 0.16405274\n",
      "2018-06-25 17:47:49 341 0.16455294\n",
      "2018-06-25 17:47:49 342 0.16517672\n",
      "2018-06-25 17:47:50 343 0.1639\n",
      "2018-06-25 17:47:50 344 0.16396067\n",
      "2018-06-25 17:47:51 345 0.1650931\n",
      "2018-06-25 17:47:52 346 0.1645499\n",
      "2018-06-25 17:47:52 347 0.1639727\n",
      "2018-06-25 17:47:53 348 0.16474059\n",
      "2018-06-25 17:47:54 349 0.16470234\n",
      "2018-06-25 17:47:54 350 0.1640148\n",
      "2018-06-25 17:47:55 351 0.16414505\n",
      "2018-06-25 17:47:56 352 0.16389273\n",
      "2018-06-25 17:47:56 353 0.16419639\n",
      "2018-06-25 17:47:57 354 0.16530792\n",
      "2018-06-25 17:47:58 355 0.16338852\n",
      "2018-06-25 17:47:59 356 0.16474456\n",
      "2018-06-25 17:47:59 357 0.16476044\n",
      "2018-06-25 17:48:00 358 0.1642952\n",
      "2018-06-25 17:48:01 359 0.16352865\n",
      "2018-06-25 17:48:01 360 0.16417915\n",
      "2018-06-25 17:48:02 361 0.16334997\n",
      "2018-06-25 17:48:03 362 0.16445462\n",
      "2018-06-25 17:48:03 363 0.16400012\n",
      "2018-06-25 17:48:04 364 0.16384888\n",
      "2018-06-25 17:48:05 365 0.16389187\n",
      "2018-06-25 17:48:06 366 0.16451257\n",
      "2018-06-25 17:48:06 367 0.16546668\n",
      "2018-06-25 17:48:07 368 0.16518949\n",
      "2018-06-25 17:48:08 369 0.16450176\n",
      "2018-06-25 17:48:08 370 0.16442704\n",
      "2018-06-25 17:48:09 371 0.16587995\n",
      "2018-06-25 17:48:10 372 0.16481249\n",
      "2018-06-25 17:48:10 373 0.16386655\n",
      "2018-06-25 17:48:11 374 0.16425525\n",
      "2018-06-25 17:48:12 375 0.16402505\n",
      "2018-06-25 17:48:12 376 0.16416635\n",
      "2018-06-25 17:48:13 377 0.1642805\n",
      "2018-06-25 17:48:13 378 0.16411369\n",
      "2018-06-25 17:48:14 379 0.16497208\n",
      "2018-06-25 17:48:15 380 0.16459797\n",
      "2018-06-25 17:48:16 381 0.16458872\n",
      "2018-06-25 17:48:17 382 0.16402721\n",
      "2018-06-25 17:48:17 383 0.164067\n",
      "2018-06-25 17:48:18 384 0.16497928\n",
      "2018-06-25 17:48:19 385 0.16510963\n",
      "2018-06-25 17:48:19 386 0.16517538\n",
      "2018-06-25 17:48:20 387 0.16459963\n",
      "2018-06-25 17:48:21 388 0.16428778\n",
      "2018-06-25 17:48:21 389 0.16382398\n",
      "2018-06-25 17:48:22 390 0.16452536\n",
      "2018-06-25 17:48:23 391 0.16474706\n",
      "2018-06-25 17:48:23 392 0.1640566\n",
      "2018-06-25 17:48:24 393 0.16393964\n",
      "2018-06-25 17:48:25 394 0.16328019\n",
      "2018-06-25 17:48:25 395 0.16571023\n",
      "2018-06-25 17:48:26 396 0.16338299\n",
      "2018-06-25 17:48:26 397 0.16494161\n",
      "2018-06-25 17:48:27 398 0.16371176\n",
      "2018-06-25 17:48:28 399 0.16475703\n",
      "2018-06-25 17:48:28 400 0.16399775\n",
      "***************************************************************第400次的准确率为0.0475\n",
      "2018-06-25 17:48:30 401 0.16370524\n",
      "2018-06-25 17:48:30 402 0.16358392\n",
      "2018-06-25 17:48:31 403 0.16487461\n",
      "2018-06-25 17:48:32 404 0.16456307\n",
      "2018-06-25 17:48:32 405 0.16417041\n",
      "2018-06-25 17:48:33 406 0.16406782\n",
      "2018-06-25 17:48:34 407 0.16475743\n",
      "2018-06-25 17:48:34 408 0.16435061\n",
      "2018-06-25 17:48:35 409 0.16418277\n",
      "2018-06-25 17:48:36 410 0.16450024\n",
      "2018-06-25 17:48:36 411 0.1642084\n",
      "2018-06-25 17:48:37 412 0.16391768\n",
      "2018-06-25 17:48:38 413 0.16336189\n",
      "2018-06-25 17:48:38 414 0.16435322\n",
      "2018-06-25 17:48:39 415 0.16473761\n",
      "2018-06-25 17:48:40 416 0.16415133\n",
      "2018-06-25 17:48:40 417 0.16287085\n",
      "2018-06-25 17:48:41 418 0.16438264\n",
      "2018-06-25 17:48:42 419 0.16338564\n",
      "2018-06-25 17:48:42 420 0.16426308\n",
      "2018-06-25 17:48:43 421 0.16494443\n",
      "2018-06-25 17:48:44 422 0.16430014\n",
      "2018-06-25 17:48:44 423 0.16397808\n",
      "2018-06-25 17:48:45 424 0.1641228\n",
      "2018-06-25 17:48:46 425 0.16402906\n",
      "2018-06-25 17:48:46 426 0.16358826\n",
      "2018-06-25 17:48:47 427 0.16343024\n",
      "2018-06-25 17:48:48 428 0.16448043\n",
      "2018-06-25 17:48:48 429 0.16467084\n",
      "2018-06-25 17:48:49 430 0.16365303\n",
      "2018-06-25 17:48:49 431 0.16427623\n",
      "2018-06-25 17:48:50 432 0.1627575\n",
      "2018-06-25 17:48:51 433 0.16377796\n",
      "2018-06-25 17:48:51 434 0.16418174\n",
      "2018-06-25 17:48:52 435 0.16411144\n",
      "2018-06-25 17:48:53 436 0.1642527\n",
      "2018-06-25 17:48:53 437 0.16316439\n",
      "2018-06-25 17:48:54 438 0.16360214\n",
      "2018-06-25 17:48:55 439 0.16399652\n",
      "2018-06-25 17:48:55 440 0.16514763\n",
      "2018-06-25 17:48:56 441 0.16475512\n",
      "2018-06-25 17:48:57 442 0.16317019\n",
      "2018-06-25 17:48:57 443 0.16523154\n",
      "2018-06-25 17:48:58 444 0.1644447\n",
      "2018-06-25 17:48:59 445 0.16527472\n",
      "2018-06-25 17:48:59 446 0.16426417\n",
      "2018-06-25 17:49:00 447 0.16413583\n",
      "2018-06-25 17:49:01 448 0.16303231\n",
      "2018-06-25 17:49:01 449 0.16383433\n",
      "2018-06-25 17:49:02 450 0.16389377\n",
      "2018-06-25 17:49:03 451 0.16494656\n",
      "2018-06-25 17:49:03 452 0.16465458\n",
      "2018-06-25 17:49:04 453 0.16402641\n",
      "2018-06-25 17:49:05 454 0.16438887\n",
      "2018-06-25 17:49:05 455 0.16439912\n",
      "2018-06-25 17:49:06 456 0.16426657\n",
      "2018-06-25 17:49:07 457 0.16503419\n",
      "2018-06-25 17:49:07 458 0.16433479\n",
      "2018-06-25 17:49:08 459 0.16318999\n",
      "2018-06-25 17:49:09 460 0.16507365\n",
      "2018-06-25 17:49:09 461 0.1642188\n",
      "2018-06-25 17:49:10 462 0.16421634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-25 17:49:10 463 0.16528855\n",
      "2018-06-25 17:49:11 464 0.16454019\n",
      "2018-06-25 17:49:12 465 0.1639503\n",
      "2018-06-25 17:49:12 466 0.16332895\n",
      "2018-06-25 17:49:13 467 0.16397944\n",
      "2018-06-25 17:49:14 468 0.16518952\n",
      "2018-06-25 17:49:14 469 0.16492847\n",
      "2018-06-25 17:49:15 470 0.16393995\n",
      "2018-06-25 17:49:15 471 0.16578947\n",
      "2018-06-25 17:49:16 472 0.16374606\n",
      "2018-06-25 17:49:17 473 0.1637199\n",
      "2018-06-25 17:49:17 474 0.16521439\n",
      "2018-06-25 17:49:18 475 0.16392669\n",
      "2018-06-25 17:49:19 476 0.16384141\n",
      "2018-06-25 17:49:19 477 0.16454172\n",
      "2018-06-25 17:49:20 478 0.16393343\n",
      "2018-06-25 17:49:21 479 0.16505815\n",
      "2018-06-25 17:49:21 480 0.16441998\n",
      "2018-06-25 17:49:22 481 0.16361508\n",
      "2018-06-25 17:49:22 482 0.16382669\n",
      "2018-06-25 17:49:23 483 0.16315982\n",
      "2018-06-25 17:49:24 484 0.16393441\n",
      "2018-06-25 17:49:24 485 0.16449125\n",
      "2018-06-25 17:49:25 486 0.1640827\n",
      "2018-06-25 17:49:26 487 0.16332276\n",
      "2018-06-25 17:49:26 488 0.16433908\n",
      "2018-06-25 17:49:27 489 0.1648075\n",
      "2018-06-25 17:49:27 490 0.16580248\n",
      "2018-06-25 17:49:28 491 0.16493279\n",
      "2018-06-25 17:49:29 492 0.16524942\n",
      "2018-06-25 17:49:29 493 0.16346414\n",
      "2018-06-25 17:49:30 494 0.16418256\n",
      "2018-06-25 17:49:31 495 0.16400307\n",
      "2018-06-25 17:49:31 496 0.16491827\n",
      "2018-06-25 17:49:32 497 0.1642108\n",
      "2018-06-25 17:49:32 498 0.16419084\n",
      "2018-06-25 17:49:33 499 0.16454591\n",
      "2018-06-25 17:49:34 500 0.16563371\n",
      "***************************************************************第500次的准确率为0.03\n",
      "2018-06-25 17:49:35 501 0.16567066\n",
      "2018-06-25 17:49:36 502 0.16353926\n",
      "2018-06-25 17:49:36 503 0.16409709\n",
      "2018-06-25 17:49:37 504 0.16433917\n",
      "2018-06-25 17:49:38 505 0.16415933\n",
      "2018-06-25 17:49:38 506 0.1642485\n",
      "2018-06-25 17:49:39 507 0.16383609\n",
      "2018-06-25 17:49:39 508 0.16391724\n",
      "2018-06-25 17:49:40 509 0.16453692\n",
      "2018-06-25 17:49:41 510 0.16429585\n",
      "2018-06-25 17:49:41 511 0.16424784\n",
      "2018-06-25 17:49:42 512 0.16431268\n",
      "2018-06-25 17:49:43 513 0.16336907\n",
      "2018-06-25 17:49:43 514 0.1634264\n",
      "2018-06-25 17:49:44 515 0.1643235\n",
      "2018-06-25 17:49:44 516 0.16431484\n",
      "2018-06-25 17:49:45 517 0.16385747\n",
      "2018-06-25 17:49:46 518 0.16447392\n",
      "2018-06-25 17:49:46 519 0.1636143\n",
      "2018-06-25 17:49:47 520 0.16472588\n",
      "2018-06-25 17:49:48 521 0.16346982\n",
      "2018-06-25 17:49:48 522 0.16319463\n",
      "2018-06-25 17:49:49 523 0.16363797\n",
      "2018-06-25 17:49:49 524 0.16376846\n",
      "2018-06-25 17:49:50 525 0.1644768\n",
      "2018-06-25 17:49:51 526 0.16399306\n",
      "2018-06-25 17:49:51 527 0.16350168\n",
      "2018-06-25 17:49:52 528 0.16458988\n",
      "2018-06-25 17:49:53 529 0.1642854\n",
      "2018-06-25 17:49:53 530 0.16404043\n",
      "2018-06-25 17:49:54 531 0.16470708\n",
      "2018-06-25 17:49:55 532 0.16485335\n",
      "2018-06-25 17:49:55 533 0.16370262\n",
      "2018-06-25 17:49:56 534 0.16440281\n",
      "2018-06-25 17:49:56 535 0.16391748\n",
      "2018-06-25 17:49:57 536 0.16429979\n",
      "2018-06-25 17:49:58 537 0.16398405\n",
      "2018-06-25 17:49:58 538 0.16464597\n",
      "2018-06-25 17:49:59 539 0.16464081\n",
      "2018-06-25 17:50:00 540 0.16378321\n",
      "2018-06-25 17:50:00 541 0.16466865\n",
      "2018-06-25 17:50:01 542 0.1648421\n",
      "2018-06-25 17:50:02 543 0.1642325\n",
      "2018-06-25 17:50:02 544 0.1639011\n",
      "2018-06-25 17:50:03 545 0.16422573\n",
      "2018-06-25 17:50:03 546 0.16426805\n",
      "2018-06-25 17:50:04 547 0.163906\n",
      "2018-06-25 17:50:05 548 0.16436861\n",
      "2018-06-25 17:50:05 549 0.16345556\n",
      "2018-06-25 17:50:06 550 0.16388725\n",
      "2018-06-25 17:50:07 551 0.1643193\n",
      "2018-06-25 17:50:07 552 0.16343679\n",
      "2018-06-25 17:50:08 553 0.16457656\n",
      "2018-06-25 17:50:08 554 0.16480222\n",
      "2018-06-25 17:50:09 555 0.16422659\n",
      "2018-06-25 17:50:10 556 0.16363849\n",
      "2018-06-25 17:50:10 557 0.16351233\n",
      "2018-06-25 17:50:11 558 0.16433512\n",
      "2018-06-25 17:50:12 559 0.16439325\n",
      "2018-06-25 17:50:12 560 0.16385292\n",
      "2018-06-25 17:50:13 561 0.16324534\n",
      "2018-06-25 17:50:14 562 0.16440725\n",
      "2018-06-25 17:50:14 563 0.16395727\n",
      "2018-06-25 17:50:15 564 0.16484088\n",
      "2018-06-25 17:50:16 565 0.16419242\n",
      "2018-06-25 17:50:16 566 0.1632523\n",
      "2018-06-25 17:50:17 567 0.16367364\n",
      "2018-06-25 17:50:17 568 0.16564022\n",
      "2018-06-25 17:50:18 569 0.16368018\n",
      "2018-06-25 17:50:19 570 0.1643355\n",
      "2018-06-25 17:50:20 571 0.16359504\n",
      "2018-06-25 17:50:20 572 0.16386034\n",
      "2018-06-25 17:50:21 573 0.16443571\n",
      "2018-06-25 17:50:22 574 0.1647342\n",
      "2018-06-25 17:50:22 575 0.16289046\n",
      "2018-06-25 17:50:23 576 0.16392271\n",
      "2018-06-25 17:50:23 577 0.1637083\n",
      "2018-06-25 17:50:24 578 0.16397426\n",
      "2018-06-25 17:50:25 579 0.16383743\n",
      "2018-06-25 17:50:25 580 0.16398528\n",
      "2018-06-25 17:50:26 581 0.16292602\n",
      "2018-06-25 17:50:27 582 0.1657617\n",
      "2018-06-25 17:50:27 583 0.16414279\n",
      "2018-06-25 17:50:28 584 0.16386738\n",
      "2018-06-25 17:50:29 585 0.16431163\n",
      "2018-06-25 17:50:29 586 0.16479826\n",
      "2018-06-25 17:50:30 587 0.16351667\n",
      "2018-06-25 17:50:31 588 0.16431317\n",
      "2018-06-25 17:50:31 589 0.1635167\n",
      "2018-06-25 17:50:32 590 0.16344236\n",
      "2018-06-25 17:50:33 591 0.1636838\n",
      "2018-06-25 17:50:33 592 0.16410509\n",
      "2018-06-25 17:50:34 593 0.16475412\n",
      "2018-06-25 17:50:35 594 0.16306421\n",
      "2018-06-25 17:50:35 595 0.16510302\n",
      "2018-06-25 17:50:36 596 0.16407917\n",
      "2018-06-25 17:50:37 597 0.16553453\n",
      "2018-06-25 17:50:38 598 0.16374995\n",
      "2018-06-25 17:50:38 599 0.16403954\n",
      "2018-06-25 17:50:39 600 0.16348329\n",
      "***************************************************************第600次的准确率为0.03\n",
      "2018-06-25 17:50:41 601 0.16417752\n",
      "2018-06-25 17:50:41 602 0.16344413\n",
      "2018-06-25 17:50:42 603 0.16437587\n",
      "2018-06-25 17:50:43 604 0.16457342\n",
      "2018-06-25 17:50:43 605 0.16418178\n",
      "2018-06-25 17:50:44 606 0.16413863\n",
      "2018-06-25 17:50:45 607 0.1645119\n",
      "2018-06-25 17:50:45 608 0.16436948\n",
      "2018-06-25 17:50:46 609 0.16447285\n",
      "2018-06-25 17:50:47 610 0.16338745\n",
      "2018-06-25 17:50:47 611 0.16472673\n",
      "2018-06-25 17:50:48 612 0.16455914\n",
      "2018-06-25 17:50:49 613 0.16367766\n",
      "2018-06-25 17:50:49 614 0.16362712\n",
      "2018-06-25 17:50:50 615 0.16387439\n",
      "2018-06-25 17:50:51 616 0.16469821\n",
      "2018-06-25 17:50:51 617 0.16412762\n",
      "2018-06-25 17:50:52 618 0.164062\n",
      "2018-06-25 17:50:53 619 0.16368087\n",
      "2018-06-25 17:50:53 620 0.16413307\n",
      "2018-06-25 17:50:54 621 0.16504867\n",
      "2018-06-25 17:50:55 622 0.16472997\n",
      "2018-06-25 17:50:55 623 0.16409151\n",
      "2018-06-25 17:50:56 624 0.16406955\n",
      "2018-06-25 17:50:57 625 0.16391295\n",
      "2018-06-25 17:50:57 626 0.16479199\n",
      "2018-06-25 17:50:58 627 0.16318175\n",
      "2018-06-25 17:50:59 628 0.1634123\n",
      "2018-06-25 17:50:59 629 0.16426101\n",
      "2018-06-25 17:51:00 630 0.16398501\n",
      "2018-06-25 17:51:00 631 0.16433801\n",
      "2018-06-25 17:51:01 632 0.1633033\n",
      "2018-06-25 17:51:02 633 0.16321784\n",
      "2018-06-25 17:51:02 634 0.16428913\n",
      "2018-06-25 17:51:03 635 0.16461317\n",
      "2018-06-25 17:51:04 636 0.16373895\n",
      "2018-06-25 17:51:04 637 0.16402332\n",
      "2018-06-25 17:51:05 638 0.16430202\n",
      "2018-06-25 17:51:06 639 0.1638743\n",
      "2018-06-25 17:51:06 640 0.16341223\n",
      "2018-06-25 17:51:07 641 0.16367975\n",
      "2018-06-25 17:51:08 642 0.16397282\n",
      "2018-06-25 17:51:08 643 0.16360143\n",
      "2018-06-25 17:51:09 644 0.16382533\n",
      "2018-06-25 17:51:10 645 0.16501266\n",
      "2018-06-25 17:51:10 646 0.16533998\n",
      "2018-06-25 17:51:11 647 0.16463171\n",
      "2018-06-25 17:51:12 648 0.16380137\n",
      "2018-06-25 17:51:12 649 0.16437568\n",
      "2018-06-25 17:51:13 650 0.16432343\n",
      "2018-06-25 17:51:14 651 0.1650049\n",
      "2018-06-25 17:51:14 652 0.16285364\n",
      "2018-06-25 17:51:15 653 0.16415985\n",
      "2018-06-25 17:51:15 654 0.1642079\n",
      "2018-06-25 17:51:16 655 0.16333665\n",
      "2018-06-25 17:51:17 656 0.1645158\n",
      "2018-06-25 17:51:17 657 0.16457063\n",
      "2018-06-25 17:51:18 658 0.16421913\n",
      "2018-06-25 17:51:19 659 0.16403145\n",
      "2018-06-25 17:51:20 660 0.16392088\n",
      "2018-06-25 17:51:20 661 0.1655671\n",
      "2018-06-25 17:51:21 662 0.16539147\n",
      "2018-06-25 17:51:22 663 0.16447727\n",
      "2018-06-25 17:51:22 664 0.16391657\n",
      "2018-06-25 17:51:23 665 0.16389531\n",
      "2018-06-25 17:51:24 666 0.16477035\n",
      "2018-06-25 17:51:24 667 0.16470185\n",
      "2018-06-25 17:51:25 668 0.16447476\n",
      "2018-06-25 17:51:25 669 0.1635219\n",
      "2018-06-25 17:51:26 670 0.16448441\n",
      "2018-06-25 17:51:27 671 0.16408738\n",
      "2018-06-25 17:51:28 672 0.16481112\n",
      "2018-06-25 17:51:28 673 0.16338983\n",
      "2018-06-25 17:51:29 674 0.16377807\n",
      "2018-06-25 17:51:29 675 0.16432096\n",
      "2018-06-25 17:51:30 676 0.16390705\n",
      "2018-06-25 17:51:31 677 0.16472325\n",
      "2018-06-25 17:51:31 678 0.16400269\n",
      "2018-06-25 17:51:32 679 0.16379213\n",
      "2018-06-25 17:51:33 680 0.16498443\n",
      "2018-06-25 17:51:33 681 0.16543533\n",
      "2018-06-25 17:51:34 682 0.1639483\n",
      "2018-06-25 17:51:35 683 0.1643458\n",
      "2018-06-25 17:51:35 684 0.16404912\n",
      "2018-06-25 17:51:36 685 0.16365579\n",
      "2018-06-25 17:51:37 686 0.16392781\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-9aabf85d4e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mtrain_crack_captcha_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-9aabf85d4e7e>\u001b[0m in \u001b[0;36mtrain_crack_captcha_cnn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "def train_crack_captcha_cnn():\n",
    "    import time\n",
    "    start_time=time.time()\n",
    "    output = crack_captcha_cnn()\n",
    "    # loss\n",
    "    #loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=Y))\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output, labels=Y))\n",
    "    # 最后一层用来分类的softmax和sigmoid有什么不同？\n",
    "    # optimizer 为了加快训练 learning_rate应该开始大，然后慢慢衰\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "    predict = tf.reshape(output, [-1, MAX_CAPTCHA, CHAR_SET_LEN])\n",
    "    max_idx_p = tf.argmax(predict, 2)\n",
    "    max_idx_l = tf.argmax(tf.reshape(Y, [-1, MAX_CAPTCHA, CHAR_SET_LEN]), 2)\n",
    "    correct_pred = tf.equal(max_idx_p, max_idx_l)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        step = 0\n",
    "        \n",
    "        while True:\n",
    "            batch_x, batch_y = get_next_batch(64)\n",
    "            _, loss_ = sess.run([optimizer, loss], feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.75})\n",
    "            print(time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),step, loss_)\n",
    "            \n",
    "            # 每100 step计算一次准确率\n",
    "            if step % 100 == 0:\n",
    "                batch_x_test, batch_y_test = get_next_batch(100)\n",
    "                acc = sess.run(accuracy, feed_dict={X: batch_x_test, Y: batch_y_test, keep_prob: 1.})\n",
    "                print(u'***************************************************************第%s次的准确率为%s'%(step, acc))\n",
    "                # 如果准确率大于50%,保存模型,完成训练\n",
    "                if acc > 0.9:                  ##我这里设了0.9，设得越大训练要花的时间越长，如果设得过于接近1，很难达到。如果使用cpu，花的时间很长，cpu占用很高电脑发烫。\n",
    "                    saver.save(sess, \"crack_capcha.model\", global_step=step)\n",
    "                    print(time.time()-start_time)\n",
    "                    break\n",
    "\n",
    "            step += 1\n",
    "\n",
    "train_crack_captcha_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 1024)\n",
      "(2, 32, 128, 1)\n",
      "(2, 16, 64, 32)\n",
      "(2, 8, 32, 64)\n",
      "(2, 4, 16, 64)\n",
      "(2, 1024)\n",
      "(2, 104)\n",
      "[[0.00719275 0.0099356  0.00979742 0.00889635 0.01055074 0.00813509\n",
      "  0.0107118  0.01169812 0.00892123 0.01056308 0.00943398 0.00951678\n",
      "  0.00907961 0.00923291 0.00979125 0.01017565 0.00905526 0.00825464\n",
      "  0.00935259 0.01027306 0.00865141 0.01021299 0.00968389 0.00937212\n",
      "  0.01034528 0.00974359 0.01116835 0.00807948 0.00943091 0.00836637\n",
      "  0.0092205  0.0110267  0.01008243 0.00935559 0.01092473 0.01121726\n",
      "  0.01140487 0.00929705 0.00852727 0.00961689 0.00956159 0.00842875\n",
      "  0.00969574 0.00848739 0.00808007 0.00941379 0.00838013 0.01100418\n",
      "  0.00832492 0.00859034 0.01113816 0.01133739 0.01010366 0.00984459\n",
      "  0.00912161 0.00959284 0.01003635 0.00891946 0.01077472 0.00920426\n",
      "  0.00960603 0.00874631 0.00990909 0.00917756 0.0080505  0.00858407\n",
      "  0.00946398 0.00950449 0.00958486 0.01033696 0.00941129 0.01019842\n",
      "  0.00943788 0.00979919 0.01075274 0.01075188 0.00754483 0.01052924\n",
      "  0.00877524 0.01067615 0.01200916 0.00802571 0.01172618 0.01044218\n",
      "  0.0096992  0.01035769 0.00971974 0.01018829 0.00998678 0.00863647\n",
      "  0.0085882  0.00926834 0.00935412 0.00955607 0.0084535  0.01057253\n",
      "  0.00851119 0.00996482 0.01008244 0.00944776 0.01079099 0.00899615\n",
      "  0.00965569 0.00879061]\n",
      " [0.00714582 0.01015222 0.00994469 0.00893387 0.01098665 0.0081682\n",
      "  0.01074668 0.01139983 0.00919856 0.01070261 0.0094454  0.00979003\n",
      "  0.0086886  0.00928522 0.00992686 0.0100868  0.00842107 0.00804582\n",
      "  0.00934602 0.01004536 0.00848148 0.01033626 0.00998219 0.00915752\n",
      "  0.01029476 0.00959428 0.01127291 0.00792445 0.00947039 0.00874396\n",
      "  0.0094936  0.01056713 0.00995252 0.00930821 0.01060629 0.01096726\n",
      "  0.01097957 0.00906289 0.00849069 0.00984939 0.00934026 0.00867156\n",
      "  0.0102067  0.00839031 0.008038   0.00934869 0.00852446 0.01108369\n",
      "  0.00828663 0.00859457 0.01107871 0.01094503 0.00984546 0.00980986\n",
      "  0.00879277 0.0094534  0.01018123 0.00887075 0.01069459 0.00910501\n",
      "  0.00980388 0.00833271 0.00985989 0.00929536 0.00802976 0.00911011\n",
      "  0.0098509  0.00926053 0.01002114 0.01081723 0.00946486 0.01058605\n",
      "  0.00951391 0.00996455 0.01076919 0.01028893 0.0072693  0.0105428\n",
      "  0.0087775  0.01083742 0.01196426 0.00817368 0.01164545 0.01043038\n",
      "  0.00941817 0.01047949 0.00968434 0.01028385 0.00992754 0.00865865\n",
      "  0.00916004 0.00920514 0.00946771 0.00918595 0.00851822 0.01027978\n",
      "  0.00849429 0.0101847  0.00994795 0.00946745 0.01084214 0.00916654\n",
      "  0.00987141 0.00888908]]\n"
     ]
    }
   ],
   "source": [
    "# test 测试 --- 不参与正常训练，学习tensorflow，查看内部变量维度使用\n",
    "w_alpha=0.01\n",
    "b_alpha=0.1\n",
    "\n",
    "x = tf.reshape(X, shape=[-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])\n",
    "\n",
    "# w_c1_alpha = np.sqrt(2.0/(IMAGE_HEIGHT*IMAGE_WIDTH)) #\n",
    "# w_c2_alpha = np.sqrt(2.0/(3*3*32))\n",
    "# w_c3_alpha = np.sqrt(2.0/(3*3*64))\n",
    "# w_d1_alpha = np.sqrt(2.0/(8*32*64))\n",
    "# out_alpha  = np.sqrt(2.0/1024)\n",
    "\n",
    "# 3 conv layer\n",
    "# [3, 3, 1, 32] 卷积核高度，宽度，输入通道数，输出通道数\n",
    "w_c1 = tf.Variable(w_alpha * tf.random_normal([3, 3, 1, 32]))\n",
    "b_c1 = tf.Variable(b_alpha * tf.random_normal([32]))\n",
    "conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c1, strides=[1, 1, 1, 1], padding='SAME'), b_c1))\n",
    "conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv1 = tf.nn.dropout(conv1, keep_prob)\n",
    "\n",
    "w_c2 = tf.Variable(w_alpha * tf.random_normal([3, 3, 32, 64]))\n",
    "b_c2 = tf.Variable(b_alpha * tf.random_normal([64]))\n",
    "conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv1, w_c2, strides=[1, 1, 1, 1], padding='SAME'), b_c2))\n",
    "conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "\n",
    "w_c3 = tf.Variable(w_alpha * tf.random_normal([3, 3, 64, 64]))\n",
    "b_c3 = tf.Variable(b_alpha * tf.random_normal([64]))\n",
    "conv3 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv2, w_c3, strides=[1, 1, 1, 1], padding='SAME'), b_c3))\n",
    "conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv3 = tf.nn.dropout(conv3, keep_prob)\n",
    "\n",
    "# Fully connected layer 输出1024维度\n",
    "w_d = tf.Variable(w_alpha * tf.random_normal([4 * 16 * 64, 1024]))\n",
    "b_d = tf.Variable(b_alpha * tf.random_normal([1024]))\n",
    "dense = tf.reshape(conv3, [-1, w_d.get_shape().as_list()[0]])\n",
    "dense = tf.nn.relu(tf.add(tf.matmul(dense, w_d), b_d))\n",
    "dense = tf.nn.dropout(dense, keep_prob)\n",
    "\n",
    "w_out = tf.Variable(w_alpha * tf.random_normal([1024, MAX_CAPTCHA * CHAR_SET_LEN]))\n",
    "b_out = tf.Variable(b_alpha * tf.random_normal([MAX_CAPTCHA * CHAR_SET_LEN]))\n",
    "out = tf.add(tf.matmul(dense, w_out), b_out)\n",
    "out = tf.nn.softmax(out)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_x,batch_y = get_next_batch(2)\n",
    "    print(w_d.shape)\n",
    "    x,conv1,conv2,conv3,dense,out = sess.run([x,conv1,conv2,conv3,dense,out], feed_dict={X:batch_x, keep_prob:0.75})\n",
    "    # 输出x的维度\n",
    "    print(x.shape)\n",
    "    print(conv1.shape)\n",
    "    print(conv2.shape)\n",
    "    print(conv3.shape)\n",
    "    print(dense.shape)\n",
    "    print(out.shape)\n",
    "    print(out)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
